{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0aef07155a9325846f45ed3c1cdbc30f5a63eae8cc52a0fa9e18e3c3c20e80faf",
   "display_name": "Python 3.8.8 64-bit ('yeonung-alphazero': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "aef07155a9325846f45ed3c1cdbc30f5a63eae8cc52a0fa9e18e3c3c20e80faf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Write submission.py"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting submission.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile submission.py\n",
    "# MIT License\n",
    "\n",
    "# Copyright (c) 2021 Choi Yeonung\n",
    "# Copyright (c) 2020 DeNA Co., Ltd.\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "import base64\n",
    "import pickle\n",
    "import zlib\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from kaggle_environments import make\n",
    "from kaggle_environments.envs.hungry_geese.hungry_geese import Action, adjacent_positions"
   ]
  },
  {
   "source": [
    "## Global variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Appending to submission.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a submission.py\n",
    "\n",
    "prev_action = None\n",
    "prev_obs = None\n",
    "env = None\n",
    "mcts = None\n",
    "state_dict = _STATE_DICT_"
   ]
  },
  {
   "source": [
    "## Neural network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Appending to submission.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a submission.py\n",
    "\n",
    "class TorusConv2d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size, bn):\n",
    "        super().__init__()\n",
    "        self.edge_size = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n",
    "        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.cat([x[:,:,:,-self.edge_size[1]:], x, x[:,:,:,:self.edge_size[1]]], dim=3)\n",
    "        h = torch.cat([h[:,:,-self.edge_size[0]:], h, h[:,:,:self.edge_size[0]]], dim=2)\n",
    "        h = self.conv(h)\n",
    "        h = self.bn(h) if self.bn is not None else h\n",
    "        return h\n",
    "\n",
    "\n",
    "class GeeseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        input_shape = (17, 7, 11)\n",
    "        layers, filters = 12, 32\n",
    "        self.conv0 = TorusConv2d(input_shape[0], filters, (3, 3), True)\n",
    "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
    "        self.head_p = nn.Linear(filters, 4, bias=False)\n",
    "        self.head_v = nn.Linear(filters * 2, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        h = F.relu_(self.conv0(x))\n",
    "        for block in self.blocks:\n",
    "            h = F.relu_(h + block(h))\n",
    "        h_head = (h * x[:,:1]).view(h.size(0), h.size(1), -1).sum(-1)\n",
    "        h_avg = h.view(h.size(0), h.size(1), -1).mean(-1)\n",
    "        p = self.head_p(h_head)\n",
    "        v = torch.tanh(self.head_v(torch.cat([h_head, h_avg], 1)))\n",
    "        return p, v"
   ]
  },
  {
   "source": [
    "## Utility functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Appending to submission.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a submission.py\n",
    "\n",
    "def find_prev_actions(curr_obs, prev_obs):\n",
    "    if prev_obs is None:\n",
    "        return [None] * 4\n",
    "\n",
    "    actions = []\n",
    "\n",
    "    prev_head_poss = [goose[0] if len(goose) else None for goose in prev_obs.geese]\n",
    "    curr_head_poss = [goose[0] if len(goose) else None for goose in curr_obs.geese]\n",
    "\n",
    "    for prev_head_pos, curr_head_pos in zip(prev_head_poss, curr_head_poss):\n",
    "        if prev_head_pos is None:\n",
    "            actions.append(None)\n",
    "            continue\n",
    "\n",
    "        adj_poss = adjacent_positions(prev_head_pos, 11, 7)\n",
    "        breaked = False\n",
    "        for action_num, adj_pos in enumerate(adj_poss, 1):\n",
    "            if adj_pos == curr_head_pos:\n",
    "                actions.append(Action(action_num).name)\n",
    "                breaked = True\n",
    "                break\n",
    "        if not breaked:\n",
    "            actions.append(None)\n",
    "\n",
    "    return actions\n",
    "\n",
    "\n",
    "def get_env(obs, config):\n",
    "    global env, prev_obs\n",
    "\n",
    "    if env is None:\n",
    "        env = make('hungry_geese')\n",
    "        env.reset(4)\n",
    "        env.state[0].observation = obs\n",
    "        env.steps[0] = env.state\n",
    "    else:\n",
    "        env.state[0].observation = obs\n",
    "        env.steps.append(env.state)\n",
    "\n",
    "    prev_actions = find_prev_actions(obs, prev_obs)\n",
    "    for i, action in enumerate(prev_actions):\n",
    "        env.state[i].action = action\n",
    "\n",
    "    return env\n",
    "\n",
    "\n",
    "def remove_illegal_action(pi, prev_action):\n",
    "    if prev_action:\n",
    "        oppo_action_value = Action.opposite(Action[prev_action]).value\n",
    "        pi[oppo_action_value - 1] = 0\n",
    "        try:\n",
    "            pi /= pi.sum()\n",
    "        except ZeroDivisionError:\n",
    "            pass\n",
    "    return pi\n",
    "\n",
    "\n",
    "def select_action(pi):\n",
    "    best_actions = np.array(np.argwhere(pi == np.max(pi))).flatten()\n",
    "    action_num = np.random.choice(best_actions) + 1\n",
    "    return Action(action_num).name"
   ]
  },
  {
   "source": [
    "## MCTS class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Appending to submission.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a submission.py\n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self, nnet, num_simuls=50, max_depth=10):\n",
    "        self.nnet = nnet\n",
    "        self.cuda = torch.cuda.is_available()\n",
    "        if self.cuda:\n",
    "            self.nnet.cuda()\n",
    "        self.nnet.eval()\n",
    "\n",
    "        self.num_simuls = num_simuls\n",
    "        self.max_depth = max_depth\n",
    "        self.c_puct = 1\n",
    "\n",
    "        self.Qsa = {}  # stores Q values for s,a (as defined in the paper)\n",
    "        self.Nsa = {}  # stores #times edge s,a was visited\n",
    "        self.Ns = {}  # stores #times board s was visited\n",
    "        self.Ps = {}  # stores initial policy (returned by neural net)\n",
    "        self.Es = {}  # stores game.getGameEnded ended for board s\n",
    "        self.Vs = {}  # stores game.getValidMoves for board s\n",
    "\n",
    "    def get_policy(self, env, prev_obs):\n",
    "        for _ in range(self.num_simuls):\n",
    "            self.search(env.clone(), prev_obs, self.max_depth)\n",
    "\n",
    "        curr_obs = env.state[0].observation\n",
    "\n",
    "        board = self.get_board(curr_obs, prev_obs)\n",
    "        board = self.get_player_board(board, curr_obs.index, 4)\n",
    "        s = board.tostring()\n",
    "\n",
    "        counts = [self.Nsa[(s, a)] if (s, a) in self.Nsa else 0 for a in range(4)]\n",
    "\n",
    "        counts = [x for x in counts]\n",
    "        counts_sum = float(sum(counts))\n",
    "        probs = np.array([x / counts_sum for x in counts])\n",
    "\n",
    "        return probs\n",
    "\n",
    "    def search(self, env, prev_obs, remaining):\n",
    "        curr_obs = env.state[0].observation\n",
    "\n",
    "        board = self.get_board(curr_obs, prev_obs)\n",
    "        board = self.get_player_board(board, curr_obs.index, 4)\n",
    "        s = board.tostring()\n",
    "\n",
    "        if s not in self.Es:\n",
    "            self.Es[s] = self.get_reward(curr_obs, curr_obs.index, 4)\n",
    "\n",
    "        if self.Es[s] is not None:  # terminal node\n",
    "            return self.Es[s]\n",
    "\n",
    "        boards = [self.get_player_board(board, player, 4) for player in range(4)]\n",
    "        boards = [torch.FloatTensor(board.astype(np.float64)) for board in boards]\n",
    "        boards = torch.stack(boards)\n",
    "        if self.cuda:\n",
    "            boards = boards.contiguous().cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pis, vs = self.nnet(boards)\n",
    "            pis = F.softmax(pis, 1).data.cpu().numpy()\n",
    "            vs = vs.data.cpu().numpy()\n",
    "\n",
    "        actions = []\n",
    "        for i, pi in enumerate(pis):\n",
    "            prev_action = env.state[i].action\n",
    "            pi = remove_illegal_action(pi, prev_action)\n",
    "            action = select_action(pi)\n",
    "            actions.append(action)\n",
    "    \n",
    "        v = vs[curr_obs.index]\n",
    "\n",
    "        if s not in self.Ps:  # leaf node\n",
    "            self.Ps[s], v = pis[curr_obs.index], v\n",
    "            policy = remove_illegal_action(self.Ps[s], env.state[curr_obs.index].action)\n",
    "            valids = np.where(policy > 0, 1, 0)\n",
    "            self.Ps[s] = self.Ps[s] * valids  # masking invalid moves\n",
    "            sum_Ps_s = np.sum(self.Ps[s])\n",
    "    \n",
    "            if sum_Ps_s > 0:\n",
    "                self.Ps[s] /= sum_Ps_s  # renormalize\n",
    "            else:\n",
    "                # log.error(\"All valid moves were masked, doing a workaround.\")\n",
    "                self.Ps[s] = self.Ps[s] + valids\n",
    "                self.Ps[s] /= np.sum(self.Ps[s])\n",
    "\n",
    "            self.Vs[s] = valids\n",
    "            self.Ns[s] = 0\n",
    "\n",
    "            return v\n",
    "\n",
    "        if remaining == 0:\n",
    "            return v\n",
    "\n",
    "        # pick the action with the highest upper confidence bound\n",
    "        valids = self.Vs[s]\n",
    "        cur_best = -float('inf')\n",
    "        best_act = -1\n",
    "        for a in range(4):\n",
    "            if valids[a]:\n",
    "                if (s, a) in self.Qsa:\n",
    "                    u = self.Qsa[(s, a)] + self.c_puct * self.Ps[s][a] * math.sqrt(self.Ns[s]) / (1 + self.Nsa[(s, a)])\n",
    "                else:\n",
    "                    u = self.c_puct * self.Ps[s][a] * math.sqrt(self.Ns[s] + 1e-8)  # Q = 0 ?\n",
    "                if u > cur_best:\n",
    "                    cur_best = u\n",
    "                    best_act = a\n",
    "        a = best_act\n",
    "\n",
    "        actions[curr_obs.index] = Action(a + 1).name\n",
    "\n",
    "        env.step(actions)\n",
    "\n",
    "        v = self.search(env, curr_obs, remaining-1)\n",
    "\n",
    "        if (s, a) in self.Qsa:\n",
    "            self.Qsa[(s, a)] = (self.Nsa[(s, a)] * self.Qsa[(s, a)] + v) / (self.Nsa[(s, a)] + 1)\n",
    "            self.Nsa[(s, a)] += 1\n",
    "        else:\n",
    "            self.Qsa[(s, a)] = v\n",
    "            self.Nsa[(s, a)] = 1\n",
    "\n",
    "        self.Ns[s] += 1\n",
    "\n",
    "        return v\n",
    "\n",
    "    def get_board(self, obs, prev_obs):\n",
    "        board = np.zeros((4 * 4 + 1, 7 * 11), np.uint8)\n",
    "\n",
    "        for i, goose in enumerate(obs.geese):\n",
    "            # head position\n",
    "            for head_pos in goose[:1]:\n",
    "                board[0 + (i - obs.index) % 4, head_pos] = 1\n",
    "\n",
    "            # tip position\n",
    "            for tip_pos in goose[-1:]:\n",
    "                board[4 + (i - obs.index) % 4, tip_pos] = 1\n",
    "\n",
    "            # whole position\n",
    "            for body_pos in goose[1:]:\n",
    "                board[4 * 2 + (i - obs.index) % 4, body_pos] = 1\n",
    "\n",
    "        # previous head position\n",
    "        if prev_obs is not None:\n",
    "            for i, goose in enumerate(prev_obs.geese):\n",
    "                for pos in goose[:1]:\n",
    "                    board[4 * 3 + (i - obs.index) % 4, pos] = 1\n",
    "\n",
    "        for food_pos in obs.food:\n",
    "            board[-1, food_pos] = 1\n",
    "\n",
    "        return board.reshape(-1, 7, 11)\n",
    "\n",
    "    def get_player_board(self, board, player, num_agents):\n",
    "        new_board = board.copy()\n",
    "        indices = np.arange(0, num_agents * 4, num_agents)\n",
    "        tmp = new_board[indices]\n",
    "        new_board[indices] = new_board[indices + player]\n",
    "        new_board[indices + player] = tmp\n",
    "        return new_board\n",
    "\n",
    "\n",
    "    def get_reward(self, obs, player, num_agents):\n",
    "        alive = 0\n",
    "        for goose in obs.geese:\n",
    "            alive += 1 if len(goose) > 0 else 0\n",
    "\n",
    "        if len(obs.geese[player]) > 0 and alive >= 2 and obs.step < 199:\n",
    "            return None\n",
    "\n",
    "        rank = 1\n",
    "        for i, goose in enumerate(obs.geese):\n",
    "            if i == player:\n",
    "                continue\n",
    "            if len(goose) > len(obs.geese[player]):\n",
    "                rank += 1\n",
    "            elif len(goose) == len(obs.geese[player]):\n",
    "                rank += 0.5\n",
    "        return (num_agents + 1 - 2 * rank) / (num_agents - 1)\n",
    "\n",
    "    "
   ]
  },
  {
   "source": [
    "## Agent function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Appending to submission.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a submission.py\n",
    "\n",
    "def agent(obs, config):\n",
    "    global state_dict, prev_action, prev_obs, mcts\n",
    "\n",
    "    if mcts is None:\n",
    "        nnet = GeeseNet()\n",
    "        state_dict = pickle.loads(zlib.decompress(base64.b64decode(state_dict)))\n",
    "        nnet.load_state_dict(state_dict)\n",
    "        mcts = MCTS(nnet)\n",
    "\n",
    "    env = get_env(obs, config)\n",
    "    policy = mcts.get_policy(env, prev_obs)\n",
    "    policy = remove_illegal_action(policy, prev_action)\n",
    "    action = select_action(policy)\n",
    "\n",
    "    prev_action = action\n",
    "    prev_obs = obs\n",
    "\n",
    "    return action"
   ]
  },
  {
   "source": [
    "# Write the weights on submission.py"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import pickle\n",
    "import zlib\n",
    "import torch\n",
    "from kaggle_environments import make\n",
    "\n",
    "loaded_model = torch.load('temp/best.pth.tar', map_location='cpu')\n",
    "state_dict = loaded_model['state_dict']\n",
    "\n",
    "new_state_dict = {}\n",
    "for key, value in state_dict.items():\n",
    "    key = key.replace(\"module.\", \"\")\n",
    "    new_state_dict[key] = value\n",
    "\n",
    "state_dict = base64.b64encode(zlib.compress(pickle.dumps(new_state_dict)))\n",
    "\n",
    "with open('submission.py', 'r') as f:\n",
    "    src = f.read()\n",
    "src = src.replace(\"_STATE_DICT_\", f\"{state_dict}\")\n",
    "with open('submission.py', 'w') as f:\n",
    "    f.write(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make(\"hungry_geese\", debug=True)\n",
    "env.run([\"submission.py\"] * 4)  # white, blue, green, red\n",
    "env.render(mode=\"ipython\", width=700, height=550)"
   ]
  }
 ]
}